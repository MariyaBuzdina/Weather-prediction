{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta, datetime\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем данные о min и max температурах\n",
    "TEMP_MAX = pd.read_csv('input/1754238.csv', delimiter=',', usecols = ['DATE', 'TMAX']) \n",
    "TEMP_MIN = pd.read_csv('input/1754238.csv', delimiter=',', usecols = ['DATE', 'TMIN']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование данныех в один dataset\n",
    "def rename_cols_rows(data, field_name):\n",
    "    date = data['DATE'].apply(pd.to_datetime, errors='ignore')\n",
    "    year = date.map(lambda x: x.year).values\n",
    "    day_month = date.map(lambda x:x.strftime('%m-%d')).unique()[0]\n",
    "    return data.drop('DATE', 1).set_index(year).rename(columns={f'{field_name}': f'{day_month}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, которая разбивает выборку по датам, напрмиер (1 января за все года)\n",
    "\n",
    "def get_df_with_day_and_month_for_all_year (df, field_name):\n",
    "    data = pd.DataFrame()\n",
    "    for month in range (1, 13):\n",
    "        for day in range(1, 32):\n",
    "            if day < 10 and month < 10: \n",
    "                pattern = r'\\d{4}-'+f'0{month}-'+f'0{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "                    pd.DataFrame(tmp).to_csv(f'{field_name}/0{month}-0{day}.csv')\n",
    "                    tmp = rename_cols_rows(tmp, field_name)\n",
    "                    data = pd.concat([data, tmp], axis = 1, join='outer', sort=True)\n",
    "                    \n",
    "            if day < 10 and month > 9: \n",
    "                pattern = r'\\d{4}-'+f'{month}-'+f'0{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "                    pd.DataFrame(tmp).to_csv(f'{field_name}/{month}-0{day}.csv')\n",
    "                    tmp = rename_cols_rows(tmp, field_name)\n",
    "                    data = pd.concat([data, tmp], axis = 1, join='outer', sort=True)\n",
    "                    \n",
    "            if day > 9 and month < 10:\n",
    "                pattern = r'\\d{4}-'+f'0{month}-'+f'{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "                    pd.DataFrame(tmp).to_csv(f'{field_name}/0{month}-{day}.csv')\n",
    "                    tmp = rename_cols_rows(tmp, field_name)\n",
    "                    data = pd.concat([data, tmp], axis = 1, join='outer', sort=True)\n",
    "                    pd.DataFrame(tmp).to_csv(f'{field_name}/0{month}-{day}.csv')\n",
    "            if day > 9 and month > 9:\n",
    "                pattern = r'\\d{4}-'+f'{month}-'+f'{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "                    pd.DataFrame(tmp).to_csv(f'{field_name}/{month}-{day}.csv')\n",
    "                    tmp = rename_cols_rows(tmp, field_name)\n",
    "                    data = pd.concat([data, tmp], axis = 1, join='outer', sort=True)\n",
    "    pd.DataFrame(data).to_csv(f'dataset{field_name}.csv')\n",
    "                   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для удоавления выбросов в столбце\n",
    "\n",
    "def delete_outliers (df):\n",
    "    q = df.quantile([0.25, 0.75])\n",
    "    # Межквартильное растояние\n",
    "    low = q[0.25] - 1.5 * (q[0.75] - q[0.25])\n",
    "    high = q[0.75] + 1.5 * (q[0.75] - q[0.25])\n",
    "    return df[df.between(low, high)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовка boxplot\n",
    "\n",
    "def draw_box_plot (df, plot_name):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    fig.suptitle(f'Boxplot for {df.name}', fontsize=14, fontweight='bold')\n",
    "    ax = fig.add_subplot(111)\n",
    "    _, bp = pd.DataFrame.boxplot(df, return_type='both', grid=False,  fontsize=15, figsize=(7,7))\n",
    "    ax.set_ylabel(f'{plot_name}, $^o C$')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = get_df_with_day_and_month_for_all_year(TEMP_MAX, 'TMAX')\n",
    "t_min = get_df_with_day_and_month_for_all_year(TEMP_MIN, 'TMIN')\n",
    "# t_avg = get_df_with_day_and_month_for_all_year(TEMP_MIN, 'TAVG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max\n",
    "# t_max['02-29'].isna()\n",
    "\n",
    "# a = t_max[['02-28', '02-29', '03-01']]\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# imp_mean.fit(a.T)\n",
    "\n",
    "\n",
    "# b = imp_mean.transform(a.T)\n",
    "# print(b[1])\n",
    "# print(t_max['02-29'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = t_max[['02-28','02-29', '03-01']]\n",
    "# tmp['02-29']  = tmp.T.apply(lambda x: (x['02-28']+x['03-01'])/2 if np.isnan(x['02-29']) else x['02-29'])\n",
    "# print(tmp)\n",
    "# for row in tmp.itertuples():\n",
    "#     print(row[2])\n",
    "# def add_value_29_02 (tmp):\n",
    "#     for row in tmp.itertuples():\n",
    "#         if row[2].isna():\n",
    "#             tmp[2] = (row[1].values + row[3].values)/2\n",
    "#         else:\n",
    "#              tmp[2] =  row[2]                \n",
    "#     return(tmp[2])\n",
    "\n",
    "# add_value_29_02 (tmp)\n",
    "# tmp['02-29'] = tmp.apply(lambda row: (row['02-28'] + row['03-01'])/2)\n",
    "# t_max['02-29']  = t_max.T.apply(lambda x: (x['02-28']+x['03-01'])/2 if np.isnan(x['02-29']) else x['02-29'])\n",
    "\n",
    "# t_min['02-29'] = t_min.T.apply(lambda x: (x['02-28']+x['03-01'])/2 if np.isnan(x['02-29']) else x['02-29'])\n",
    "t_max = t_max.drop('02-29', 1)\n",
    "t_min = t_min.drop('02-29', 1)\n",
    "# t_avg = t_avg.drop('02-29', 1)\n",
    "# t_min['02-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_box_plot(t_max['03-26'], 'TMAX')\n",
    "draw_box_plot(t_min['03-26'], 'TMIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание тренировочного и тестового набора для проверки работы моделей\n",
    "\n",
    "def create_train_and_test_datasets (data):\n",
    "    data = data.dropna()\n",
    "#     .apply(lambda x: delete_outliers(x)).dropna()\n",
    "    X, y = data.T.iloc[:, :-1].values, data.T.iloc[:, -1]\n",
    "#     X_test, y_test = data.T.iloc[:, 1:-1].values, data.T.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "#     X_train, X_test, y_train, y_test = np.array(X[:-8]), np.array(X[-8:-7]), np.array(y[:-8]), np.array(y[-8:-7])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стандартизация datasets для использования в моеделях\n",
    "\n",
    "def standartization_dataset (X_train, X_test):\n",
    "    stdsc = StandardScaler()\n",
    "    X_train_std = stdsc.fit_transform(X_train)\n",
    "    X_test_std = stdsc.transform(X_test)\n",
    "    return X_train_std, X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_dataset (X_train, X_test):\n",
    "    ms = MinMaxScaler(feature_range=(0,1))\n",
    "    X_train_n = ms.fit_transform(X_train)\n",
    "    X_test_n = ms.transform(X_test)\n",
    "    return X_train_n, X_test_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовка столбчатых диаграм для оценки работы моделей\n",
    "\n",
    "def draw_bar(df, field_name):\n",
    "    df.plot.bar(color = [\"dodgerblue\", 'r', 'darkmagenta', 'c'], figsize=(7,7))\n",
    "    plt.xticks(rotation=75)  \n",
    "    plt.ylabel(f'{field_name}')    \n",
    "    plt.title(f'{field_name}', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "def draw_pie(df, field_name):\n",
    "    df.plot.pie(subplots=True, figsize=(10,10), colormap='jet') \n",
    "    plt.title(f'{field_name}', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(f' ')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Полученеие данных о модели\n",
    "\n",
    "def estimate_model (model, X_train, y_train, y_test, prediction, model_name):\n",
    "    score = model.score(X_train, y_train)\n",
    "    MAE = mean_absolute_error(y_test, prediction)\n",
    "    MSE = mean_squared_error(y_test, prediction)\n",
    "    print(f'\\n{model_name}')\n",
    "    print(\"The Explained Variance: %.2f\" % score)\n",
    "    print(\"The Mean Absolute Error: %.2f degrees celsius\" % MAE)\n",
    "    print('The Square Error: %.2f' % MSE)\n",
    "    return pd.DataFrame({\"Score\": score, 'MAE': MAE, 'MSE': MSE}, index=[f'{model_name}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_delta(y_test, prediction, name):\n",
    "    DELTA = abs(y_test - prediction)\n",
    "    less_one_degrees = DELTA.apply(lambda x: x < 1).value_counts()/DELTA.size*100\n",
    "    less_three_degrees = DELTA.apply(lambda x: 1< x < 3).value_counts()/DELTA.size*100\n",
    "    less_five_degrees = DELTA.apply(lambda x: 3 < x < 5).value_counts()/DELTA.size*100\n",
    "    gr_five_degrees = DELTA.apply(lambda x:  x > 5).value_counts()/DELTA.size*100\n",
    "    df = pd.DataFrame({\"Ошибка меньше 1 градуса\": less_one_degrees.drop(less_one_degrees.index[0]), \"Ошибка от 1 до 3 градусов\": less_three_degrees.drop(less_three_degrees.index[0]),\n",
    "                       'Ошибка от 3 до 5 градусов': less_five_degrees.drop(less_five_degrees.index[0]), \n",
    "                       'Ошибка больше 5 градусов': gr_five_degrees.drop(gr_five_degrees.index[0])})\n",
    "    draw_pie(df.T, f'Ошибки в прогнозировании {name}')\n",
    "    print(df)\n",
    "#     df.T.plot.pie(subplots=True, figsize=(7,7))\n",
    "#     ig = plt.figure(figsize=(6,6), dpi=200)\n",
    "#     ax = plt.subplot(True)\n",
    "\n",
    "#     df.plot(kind='pie', ax=ax, autopct='%1.1f%%', startangle=270, fontsize=17, color = [\"dodgerblue\", 'r', 'darkmagenta', 'c'])\n",
    "#     print(\"Меньше 1 градуса\\n\", less_one_degrees)\n",
    "#     print(\"От 1 до 3 градусов\\n\", less_three_degrees.value_counts()/DELTA.size*100)\n",
    "#     print(\"От 3 до 5 градусов\\n\", less_five_degrees.value_counts()/DELTA.size*100)\n",
    "#     print(\"Больше 5 градусов\\n\", gr_five_degrees.value_counts()/DELTA.size*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_max, X_test_max, y_train_max, y_test_max = create_train_and_test_datasets(t_max)\n",
    "X_train_min, X_test_min, y_train_min, y_test_min = create_train_and_test_datasets(t_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserch_prediction(data, field_name):\n",
    "    X_train, X_test, y_train, y_test = create_train_and_test_datasets(data)\n",
    "    X_train_std, X_test_std = standartization_dataset (X_train, X_test)\n",
    "    X_train_n, X_test_n = normalization_dataset (X_train, X_test)\n",
    "#     print(X_test, X_test.shape)\n",
    "#     print(y_test, y_test.shape)\n",
    "#     x = X_train[0]\n",
    "#     z = X_train_std[0]\n",
    "#     p = X_train_n[0]\n",
    "#     print(y_train[0])\n",
    "#     np.array(data.dropna().T.iloc[10:12, 0:-1].values)\n",
    "#     print([x], [x].shape)\n",
    "    LR = LinearRegression()\n",
    "    LR.fit(X_train, y_train)\n",
    "    svr = SVR(C=100.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "        gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "        tol=0.001, verbose=False)\n",
    "    svr.fit(X_train_std, y_train)\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(2,), max_iter=5000, \n",
    "                       activation='relu', solver='adam', alpha=0.001,\n",
    "                               random_state=1, learning_rate_init=0.01)\n",
    "    mlp.fit(X_train_n, y_train)\n",
    "    random_forest = RandomForestRegressor(max_depth=10, random_state=0,\n",
    "                                 n_estimators=1000)\n",
    "    random_forest.fit(X_train, y_train) \n",
    "\n",
    "    prediction_LR = np.array([])\n",
    "    prediction_RF = np.array([])\n",
    "    prediction_mlp = np.array([])\n",
    "    prediction_SVM = np.array([])\n",
    "    \n",
    "    for x_test in X_test:\n",
    "        prediction_LR = np.append(prediction_LR, LR.predict([x_test]))\n",
    "        prediction_RF = np.append(prediction_RF, random_forest.predict([x_test]))\n",
    "    for i in X_test_std:\n",
    "        prediction_SVM = np.append(prediction_SVM, svr.predict([i]))\n",
    "    for i in X_test_n:\n",
    "        prediction_mlp = np.append(prediction_mlp, mlp.predict([i]))\n",
    "    \n",
    "#     df1 =  df1 = pd.DataFrame(\n",
    "#         {'TEMP_SVM': svr.predict([z]), 'TEMP_MLP': mlp.predict([p]), 'TEMP_RF': random_forest.predict([x])})\n",
    "#     print(df1)\n",
    "    \n",
    "    \n",
    "#     estimate_LR = estimate_model(LR, X_train, y_train, y_test, prediction_LR, f\"LR {field_name}\")\n",
    "    estimate_RF = estimate_model(random_forest, X_train, y_train, y_test, prediction_RF, f\"RF {field_name}\")\n",
    "    estimate_delta(y_test, prediction_RF, 'RF')\n",
    "    estimate_SVM = estimate_model(svr, X_train_std, y_train, y_test, prediction_SVM, f\"SVM {field_name}\")\n",
    "    estimate_delta(y_test, prediction_SVM, 'SVM')\n",
    "    estimate_MLP = estimate_model(mlp, X_train_n, y_train, y_test, prediction_mlp, f\"MLP {field_name}\")\n",
    "    estimate_delta(y_test, prediction_mlp, 'MLP')\n",
    "    \n",
    "    estimate = pd.concat([estimate_SVM, estimate_MLP, estimate_RF], axis = 0, join='outer', sort=True)\n",
    "    \n",
    "    df = pd.DataFrame({'TEMP': y_test, 'TEMP_LR': prediction_LR, 'TEMP_SVM': prediction_SVM, 'TEMP_MLP': prediction_mlp, 'TEMP_RF': prediction_RF})\n",
    "    df.plot(y = ['TEMP', 'TEMP_SVM'],color = [\"dodgerblue\", 'r'], style = ['', '--'],linewidth=1, figsize=(25,10), )\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=75)\n",
    "    plt.xlabel('Date')    \n",
    "    plt.ylabel(f'{field_name} temperature, $^o, C$')    \n",
    "    plt.title(f'Предсказание {field_name} температуры моделю SVM', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    df.plot(y = ['TEMP', 'TEMP_MLP'],color = [\"dodgerblue\", 'darkmagenta'], style = ['',  ':'],linewidth=1, figsize=(25,10), )\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=75)\n",
    "    plt.xlabel('Date')    \n",
    "    plt.ylabel(f'{field_name} temperature, $^o, C$')    \n",
    "    plt.title(f'Предсказание {field_name} температуры моделю MLP', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    df.plot(y = ['TEMP', 'TEMP_RF'],color = [\"dodgerblue\", 'y'], style = ['',  '-.'],linewidth=1, figsize=(25,10), )\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=75)\n",
    "    plt.xlabel('Date')    \n",
    "    plt.ylabel(f'{field_name} temperature, $^o, C$')    \n",
    "    plt.title(f'Предсказание {field_name} температуры моделью RF', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    return  df, estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max, estimate_max = reserch_prediction(t_max, 'MAX')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bar(estimate_max['Score'], 'Коэффициент детерминизации')\n",
    "draw_bar(estimate_max['MAE'], 'MAE')\n",
    "draw_bar(estimate_max['MSE'], 'MSE')\n",
    "estimate_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min, estimate_min = reserch_prediction(t_min, 'MIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bar(estimate_min['Score'], 'Коэффициент детерминизации')\n",
    "draw_bar(estimate_min['MAE'], 'MAE')\n",
    "draw_bar(estimate_min['MSE'], 'MSE')\n",
    "estimate_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserch_prediction(data, field_name):\n",
    "    X_train, X_test, y_train, y_test = create_train_and_test_datasets(data)\n",
    "    X_train_std, X_test_std = standartization_dataset(X_train, X_test)\n",
    "    X_train_n, X_test_n = normalization_dataset(X_train, X_test)\n",
    "\n",
    "    LR = LinearRegression()\n",
    "    LR.fit(X_train, y_train)\n",
    "    prediction_LR = LR.predict(X_test)\n",
    "    estimate_LR = estimate_model(LR, X_train, y_train, y_test, prediction_LR, f\"LR {field_name}\")\n",
    "\n",
    "    svr = SVR(C=100.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "              gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "              tol=0.001, verbose=False)\n",
    "    svr.fit(X_train_std, y_train)\n",
    "    prediction_SVM = svr.predict(X_test_std)\n",
    "    estimate_SVM = estimate_model(svr, X_train_std, y_train, y_test, prediction_SVM, f\"SVM {field_name}\")\n",
    "\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(3,), max_iter=5000,\n",
    "                       activation='relu', solver='adam', alpha=0.001,\n",
    "                       random_state=1, learning_rate_init=0.01)\n",
    "    mlp.fit(X_train_n, y_train)\n",
    "    prediction_mlp = mlp.predict(X_test_n)\n",
    "    estimate_MLP = estimate_model(mlp, X_train_n, y_train, y_test, prediction_mlp, f\"MLP {field_name}\")\n",
    "\n",
    "    random_forest = RandomForestRegressor(max_depth=10, random_state=0,\n",
    "                                          n_estimators=1000)\n",
    "    random_forest.fit(X_train, y_train)\n",
    "    prediction_RF = random_forest.predict(X_test)\n",
    "    estimate_RF = estimate_model(random_forest, X_train, y_train, y_test, prediction_RF, f\"RF {field_name}\")\n",
    "\n",
    "    svm = SVR(C=100.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "              gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "              tol=0.001, verbose=False)\n",
    "\n",
    "    rf = RandomForestRegressor(max_depth=2, random_state=0,\n",
    "                               n_estimators=100)\n",
    "\n",
    "    estimate = pd.concat([estimate_LR, estimate_SVM, estimate_MLP, estimate_RF], axis=0, join='outer', sort=True)\n",
    "\n",
    "    df = pd.DataFrame({'TEMP': y_test, 'TEMP_LR': prediction_LR, 'TEMP_SVM': prediction_SVM, 'TEMP_MLP': prediction_mlp,\n",
    "                       'TEMP_RF': prediction_RF})\n",
    "    df.plot(y=['TEMP', 'TEMP_SVM', 'TEMP_MLP', 'TEMP_RF'], color=[\"dodgerblue\", 'r', 'darkmagenta', 'c', 'y'],\n",
    "            style=['', '--', ':', '-.', ''], linewidth=1, figsize=(25, 10), )\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=75)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'{field_name} temperature, $^o, C$')\n",
    "    plt.title(f'Предсказание {field_name} температуры', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "    return df, estimate\n",
    "\n",
    "# Считываем данные о min и max температурах\n",
    "\n",
    "df_max, estimate_max = reserch_prediction(t_max, 'MAX')\n",
    "draw_bar(estimate_max['Score'], 'Коэффициент детерминизации')\n",
    "draw_bar(estimate_max['MAE'], 'MAE')\n",
    "draw_bar(estimate_max['MSE'], 'MSE')\n",
    "\n",
    "df_min, estimate_min = reserch_prediction(t_min, 'MIN')\n",
    "draw_bar(estimate_min['Score'], 'Коэффициент детерминизации')\n",
    "draw_bar(estimate_min['MAE'], 'MAE')\n",
    "draw_bar(estimate_min['MSE'], 'MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "prediction1 = regressor.predict(X_test)\n",
    "\n",
    "print(\"The Explained Variance: %.2f\" % regressor.score(X_train, y_train))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction1))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction1))\n",
    "print('The Square Error: %.2f' % mean_squared_error(y_test, prediction1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = data.T.iloc[:, :-1].values, data.T.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0, random_state=0)\n",
    "X_test = np.array(X[1:])\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "#Fitting the Classifier\n",
    "SVR = SVR(C=100.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "    tol=0.001    data = data.dropna()\n",
    "#     apply(lambda x: delete_outliers(x)).dropna()\n",
    "    X, y = data.T.iloc[:, :-1].values, data.T.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0), verbose=False)\n",
    "\n",
    "SVR.fit(X_train_std, y_train)\n",
    "\n",
    "prediction = SVR.predict(X_test_std)\n",
    "print(\"SVM\")\n",
    "print('The Explained Variance: %.2f' % SVR.score(X_train_std, y_train))\n",
    "# print('The Mean Absolute Error: %.2f degrees celcius' % mean_absolute_error(\n",
    "#     y_test, prediction))\n",
    "# print('The Median Absolute Error: %.2f degrees celcius' %\n",
    "#       median_absolute_error(y_test, prediction))\n",
    "# print('The Square Error: %.2f' %\n",
    "#       mean_squared_error(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ms = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_n = ms.fit_transform(X_train)\n",
    "X_test_n = ms.transform(X_test)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(3,), max_iter=5000, \n",
    "                   activation='relu', solver='adam', alpha=0.001,\n",
    "                           random_state=1, learning_rate_init=0.01)\n",
    "mlp.fit(X_train_n, y_train)\n",
    "prediction_mlp = mlp.predict(X_test_n)\n",
    "\n",
    "print('\\nMLP')\n",
    "print(\"The Explained Variance: %.2f\" % mlp.score(X_train_n, y_train))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction_mlp))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction_mlp))\n",
    "print('The Square Error: %.2f' % mean_squared_error(y_test, prediction_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# clf = DecisionTreeRegressor()\n",
    "# clf = clf.fit(X_train_n, y_train)\n",
    "# prediction_DT = clf.predict(X_test_n)\n",
    "\n",
    "# print('\\nDecision Tree')\n",
    "# print(\"The Explained Variance: %.2f\" % mlp.score(X_train_n, y_train))  \n",
    "# print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction_DT))  \n",
    "# print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction_DT))\n",
    "# print('The Square Error: %.2f' % mean_squared_error(y_test, prediction_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "                      \n",
    "regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
    "        n_estimators=1000, random_state=0)\n",
    "regr.fit(X_train_std, y_train)  \n",
    "\n",
    "prediction_Ada_Boost = regr.predict(X_test_std)\n",
    "\n",
    "print('\\nAda Boost')\n",
    "print(\"The Explained Variance: %.2f\" % regr.score(X_train_std, y_train))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction_Ada_Boost))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction_Ada_Boost))\n",
    "print('The Square Error: %.2f' % mean_squared_error(y_test, prediction_Ada_Boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "X, y = data.T.iloc[:, :-1].values, data.T.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = np.array(X[:-1]), np.array(X[-1:]), np.array(y[:-1]), np.array(y[-1:])\n",
    "X_test2, y_test2 =  np.array(X[-2:-1]), np.array(y[-2:-1])\n",
    "\n",
    "\n",
    "random_forest = RandomForestRegressor(max_depth=10, random_state=0,\n",
    "                             n_estimators=1000)\n",
    "random_forest.fit(X_train, y_train) \n",
    "prediction_RF_1 = random_forest.predict(X_test)\n",
    "prediction_RF_2 = random_forest.predict(X_test2)\n",
    "\n",
    "print(prediction_RF_1, prediction_RF_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'TEMP': y_test, 'TEMP_LR': prediction1, 'TEMP_SCR': prediction, 'TEMP_MLP': prediction_mlp, 'TEMP_RF': prediction_RF})\n",
    "\n",
    "df.plot(y = ['TEMP', 'TEMP_SCR', 'TEMP_MLP', 'TEMP_RF'],color = [\"dodgerblue\", 'r', 'y', 'g', 'darkmagenta', 'pink'], style = ['', '--', '-', '-.', ''],linewidth=1, figsize=(25,10), )\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=75)\n",
    "plt.xlabel('Date')    \n",
    "plt.ylabel('Max temperature, $^o, C$')    \n",
    "plt.title('Предсказание  максимальной температуры', fontsize=14, fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(t_max[['01-02']])  \n",
    "\n",
    "B = np.round(imp.transform(t_max[['01-01']]), 2)\n",
    "# print(B)\n",
    "b = t_max.apply(lambda x: np.round(imp.transform(pd.DataFrame(x)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserch_prediction(data, field_name):\n",
    "    X_train, X_test, y_train, y_test = create_train_and_test_datasets(data)\n",
    "    X_train_std, X_test_std = standartization_dataset (X_train, X_test)\n",
    "    X_train_n, X_test_n = normalization_dataset (X_train, X_test)\n",
    "#     print(X_test, X_test.shape)\n",
    "#     print(y_test, y_test.shape)\n",
    "#     x = X_train[0]\n",
    "#     z = X_train_std[0]\n",
    "#     p = X_train_n[0]\n",
    "#     print(y_train[0])\n",
    "#     np.array(data.dropna().T.iloc[10:12, 0:-1].values)\n",
    "#     print([x], [x].shape)\n",
    "    LR = LinearRegression()\n",
    "    LR.fit(X_train, y_train)\n",
    "    svr = SVR(C=100.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "        gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "        tol=0.001, verbose=False)\n",
    "    svr.fit(X_train_std, y_train)\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(3,), max_iter=5000, \n",
    "                       activation='relu', solver='adam', alpha=0.001,\n",
    "                               random_state=1, learning_rate_init=0.01)\n",
    "    mlp.fit(X_train_n, y_train)\n",
    "    random_forest = RandomForestRegressor(max_depth=10, random_state=0,\n",
    "                                 n_estimators=1000)\n",
    "    random_forest.fit(X_train, y_train) \n",
    "\n",
    "    prediction_LR = np.array([])\n",
    "    prediction_RF = np.array([])\n",
    "    prediction_mlp = np.array([])\n",
    "    prediction_SVM = np.array([])\n",
    "    \n",
    "    for x_test in X_test:\n",
    "        prediction_LR = np.append(prediction_LR, LR.predict([x_test]))\n",
    "        prediction_RF = np.append(prediction_RF, random_forest.predict([x_test]))\n",
    "    for i in X_test_std:\n",
    "        prediction_SVM = np.append(prediction_SVM, svr.predict([i]))\n",
    "    for i in X_test_n:\n",
    "        prediction_mlp = np.append(prediction_mlp, mlp.predict([i]))\n",
    "    \n",
    "#     df1 =  df1 = pd.DataFrame(\n",
    "#         {'TEMP_SVM': svr.predict([z]), 'TEMP_MLP': mlp.predict([p]), 'TEMP_RF': random_forest.predict([x])})\n",
    "#     print(df1)\n",
    "    \n",
    "    \n",
    "#     estimate_LR = estimate_model(LR, X_train, y_train, y_test, prediction_LR, f\"LR {field_name}\")\n",
    "    estimate_RF = estimate_model(random_forest, X_train, y_train, y_test, prediction_RF, f\"RF {field_name}\")\n",
    "    estimate_SVM = estimate_model(svr, X_train_std, y_train, y_test, prediction_SVM, f\"SVM {field_name}\")\n",
    "    estimate_MLP = estimate_model(mlp, X_train_n, y_train, y_test, prediction_mlp, f\"MLP {field_name}\")\n",
    "    \n",
    "    estimate = pd.concat([estimate_SVM, estimate_MLP, estimate_RF], axis = 0, join='outer', sort=True)\n",
    "    \n",
    "    df = pd.DataFrame({'TEMP': y_test, 'TEMP_LR': prediction_LR, 'TEMP_SVM': prediction_SVM, 'TEMP_MLP': prediction_mlp, 'TEMP_RF': prediction_RF})\n",
    "    df.plot(y = ['TEMP', 'TEMP_SVM', 'TEMP_MLP', 'TEMP_RF'],color = [\"dodgerblue\", 'r', 'darkmagenta', 'c', 'y'], style = ['', '--', ':', '-.', ''],linewidth=1, figsize=(25,10), )\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=75)\n",
    "    plt.xlabel('Date')    \n",
    "    plt.ylabel(f'{field_name} temperature, $^o, C$')    \n",
    "    plt.title(f'Предсказание {field_name} температуры', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    return  df, estimate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
