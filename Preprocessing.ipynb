{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta, datetime\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Считываем данные о min и max температурах\n",
    "TEMP = pd.read_csv('input/Saint-Petersburg(1881).csv', delimiter=',', usecols = ['DATE', 'TAVG', 'PRCP', 'TMAX', 'TMIN']) \n",
    "TEMP_MAX = pd.read_csv('input/Saint-Petersburg(1881).csv', delimiter=',', usecols = ['DATE', 'TMAX']) \n",
    "TEMP_MIN = pd.read_csv('input/Saint-Petersburg(1881).csv', delimiter=',', usecols = ['DATE', 'TMIN']) \n",
    "\n",
    "# Приводит столбец дата, к формату datetime\n",
    "# TEMP_MIN['DATE'] = TEMP_MIN['DATE'].apply(pd.to_datetime, errors='ignore') \n",
    "# TEMP_MAX['DATE'] = TEMP_MIN['DATE'].apply(pd.to_datetime, errors='ignore') \n",
    "# TEMP.info()\n",
    "# print('______________________')\n",
    "# TEMP_MAX.info()\n",
    "# print('______________________')\n",
    "# TEMP_MIN.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, которая разбивает выборку по датам, напрмиер (1 января за все года)\n",
    "\n",
    "def rename_cols_rows(data):\n",
    "    date = data['DATE'].apply(pd.to_datetime, errors='ignore')\n",
    "    year = date.map(lambda x: x.year).values\n",
    "    day_month = date.map(lambda x:x.strftime('%m-%d')).unique()[0]\n",
    "    return data.drop('DATE', 1).set_index(year).rename(columns={'TMAX': f'{day_month}'})\n",
    "\n",
    "# df = pd.concat([df, tmp], axis = 1, join='outer', sort=True)\n",
    "\n",
    "def get_df_with_day_and_month_for_all_year (df):\n",
    "    data = pd.DataFrame()\n",
    "    for day in range(1, 32):\n",
    "        for month in range (1, 13):\n",
    "            if day < 10 and month < 10: \n",
    "                pattern = r'\\d{4}-'+f'0{month}-'+f'0{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "                    tmp = rename_cols_rows(tmp)\n",
    "                    data = pd.concat([data, tmp], axis = 1, join='outer', sort=True)\n",
    "#                     print(tmp)\n",
    "                    pd.DataFrame(tmp).to_csv(f'Preprocessing/0{month}-0{day}.csv')\n",
    "            if day < 10 and month > 9: \n",
    "                pattern = r'\\d{4}-'+f'{month}-'+f'0{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "                    tmp = rename_cols_rows(tmp)\n",
    "                    data = pd.concat([data, tmp], axis = 1, join='outer', sort=True)\n",
    "#                     print(tmp)\n",
    "                    pd.DataFrame(tmp).to_csv(f'Preprocessing/{month}-0{day}.csv')\n",
    "            if day > 9 and month < 10:\n",
    "                pattern = r'\\d{4}-'+f'0{month}-'+f'{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "                    tmp = rename_cols_rows(tmp)\n",
    "                    data = pd.concat([data, tmp], axis = 1, join='outer', sort=True)\n",
    "#                     print(tmp)\n",
    "                    pd.DataFrame(tmp).to_csv(f'Preprocessing/0{month}-{day}.csv')\n",
    "            if day > 9 and month > 9:\n",
    "                pattern = r'\\d{4}-'+f'{month}-'+f'{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "                    tmp = rename_cols_rows(tmp)\n",
    "                    data = pd.concat([data, tmp], axis = 1, join='outer', sort=True)\n",
    "#                     print(tmp)\n",
    "                    pd.DataFrame(tmp).to_csv(f'Preprocessing/{month}-{day}.csv')\n",
    "    return data\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_df_with_day_and_month_for_all_year1 (df):\n",
    "    amount = 0\n",
    "    am = 0\n",
    "    for day in range(1, 32):\n",
    "        for month in range (1, 13):\n",
    "            if day < 10 and month < 10: \n",
    "                pattern = r'\\d{4}-'+f'0{month}-'+f'0{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "#                     tmp = rename_cols_rows(tmp)\n",
    "#                     print(tmp)\n",
    "                    pd.DataFrame(tmp).to_csv(f'Preprocessing1/0{month}-0{day}.csv')\n",
    "            if day < 10 and month > 9: \n",
    "                pattern = r'\\d{4}-'+f'{month}-'+f'0{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "#                     tmp = rename_cols_rows(tmp)\n",
    "#                     print(tmp)\n",
    "                    pd.DataFrame(tmp).to_csv(f'Preprocessing1/{month}-0{day}.csv')\n",
    "            if day > 9 and month < 10:\n",
    "                pattern = r'\\d{4}-'+f'0{month}-'+f'{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "#                     tmp = rename_cols_rows(tmp)\n",
    "#                     print(tmp)\n",
    "                    pd.DataFrame(tmp).to_csv(f'Preprocessing1/0{month}-{day}.csv')\n",
    "            if day > 9 and month > 9:\n",
    "                pattern = r'\\d{4}-'+f'{month}-'+f'{day}'\n",
    "                tmp = df[df['DATE'].str.match(pattern)]\n",
    "                if not tmp.empty:\n",
    "#                     tmp = rename_cols_rows(tmp)\n",
    "#                     print(tmp)\n",
    "                    pd.DataFrame(tmp).to_csv(f'Preprocessing/{month}-{day}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_outliers (df, field_name):\n",
    "    q = df[field_name].quantile([0.25, 0.75])\n",
    "    # Межквартильное растояние\n",
    "    low = q[0.25] - 1.5 * (q[0.75] - q[0.25])\n",
    "    high = q[0.75] + 1.5 * (q[0.75] - q[0.25])\n",
    "    return df[df[field_name].between(low, high)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box_plot (df, plot_name):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    fig.suptitle(f'Boxplot for {df.name}', fontsize=14, fontweight='bold')\n",
    "    ax = fig.add_subplot(111)\n",
    "    _, bp = pd.DataFrame.boxplot(df, return_type='both', grid=False,  fontsize=15, figsize=(7,7))\n",
    "    ax.set_ylabel(f'{plot_name}, $^o C$')\n",
    "    plt.show()\n",
    "\n",
    "#     outliers_max = [flier.get_ydata() for flier in bp[\"fliers\"]]\n",
    "#     print('Выбросы:', outliers_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = get_df_with_day_and_month_for_all_year(TEMP_MAX)\n",
    "# get_df_with_day_and_month_for_all_year1(TEMP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'03-21'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_box_plot(t['03-21'], 'TMAX')\n",
    "t['03-21'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_outliers (df):\n",
    "    q = df.quantile([0.25, 0.75])\n",
    "    # Межквартильное растояние\n",
    "    low = q[0.25] - 1.5 * (q[0.75] - q[0.25])\n",
    "    high = q[0.75] + 1.5 * (q[0.75] - q[0.25])\n",
    "    return df[df.between(low, high)]\n",
    "\n",
    "a = t.apply(lambda x: delete_outliers(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>02-28</th>\n",
       "      <th>02-29</th>\n",
       "      <th>03-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>-11.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>-9.6</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>-6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>-9.4</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>-2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>-4.1</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>-9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>-3.6</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>-1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>-4.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>-4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>-7.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>-2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>-12.4</td>\n",
       "      <td>-10.3</td>\n",
       "      <td>-3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>-4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>-1.8</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>-4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>2.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>-2.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>-7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>6.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>-1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>-9.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>-6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>-1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>-4.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>-4.3</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>4.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>-11.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      02-28  02-29  03-01\n",
       "1881  -11.7    NaN   -8.5\n",
       "1882    NaN    NaN    NaN\n",
       "1883    NaN    NaN    NaN\n",
       "1884   -9.6   -6.5   -6.7\n",
       "1885    3.1    NaN    0.5\n",
       "1886   -6.1    NaN   -5.7\n",
       "1887    3.8    NaN    4.4\n",
       "1888   -9.4   -8.1   -2.7\n",
       "1889   -5.0    NaN   -9.4\n",
       "1890   -6.0    NaN   -6.5\n",
       "1891    3.5    NaN    1.0\n",
       "1892   -4.1   -3.4  -10.9\n",
       "1893    2.6    NaN    1.9\n",
       "1894    2.6    NaN    0.6\n",
       "1895   -9.2    NaN  -10.3\n",
       "1896   -3.6   -4.8   -5.8\n",
       "1897   -1.7    NaN   -4.6\n",
       "1898   -4.4    NaN   -0.1\n",
       "1899   -4.1    NaN    0.2\n",
       "1900   -7.3    NaN   -8.5\n",
       "1901    1.4    NaN    0.8\n",
       "1902   -2.6    NaN    1.1\n",
       "1903    NaN    NaN    NaN\n",
       "1904  -12.4  -10.3   -3.2\n",
       "1905   -4.2    NaN    0.5\n",
       "1906    2.2    NaN    2.1\n",
       "1907   -4.0    NaN   -0.3\n",
       "1908   -1.8   -1.8   -3.3\n",
       "1909   -4.2    NaN   -5.5\n",
       "1910    2.1    NaN    3.3\n",
       "...     ...    ...    ...\n",
       "1990    4.5    NaN    2.2\n",
       "1991   -1.2    NaN   -0.1\n",
       "1992    2.1    3.1    3.0\n",
       "1993   -2.9    NaN   -1.1\n",
       "1994   -7.6    NaN   -8.4\n",
       "1995    2.2    NaN    3.4\n",
       "1996    0.0   -1.5   -2.2\n",
       "1997    1.4    NaN    2.8\n",
       "1998    4.2    NaN    2.3\n",
       "1999   -3.1    NaN    0.6\n",
       "2000    6.2    6.8    4.3\n",
       "2001   -4.5    NaN   -2.5\n",
       "2002    3.4    NaN    0.0\n",
       "2003   -1.8    NaN   -4.5\n",
       "2004   -0.3   -1.2   -2.9\n",
       "2005   -9.2    NaN  -10.0\n",
       "2006   -6.2    NaN   -2.6\n",
       "2007   -1.1    NaN    0.4\n",
       "2008    4.5    1.6    1.7\n",
       "2009    2.2    NaN   -0.1\n",
       "2010    2.2    NaN    1.7\n",
       "2011   -4.1    NaN   -7.3\n",
       "2012   -4.3   -1.4    3.9\n",
       "2013    2.2    NaN    1.0\n",
       "2014    NaN    NaN    NaN\n",
       "2015    NaN    NaN    3.9\n",
       "2016    NaN    NaN    1.7\n",
       "2017    4.4    NaN    NaN\n",
       "2018  -11.7    NaN    NaN\n",
       "2019    NaN    NaN    NaN\n",
       "\n",
       "[139 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[['02-28', '02-29', '03-01']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['02-29'] = (t['02-28'].values + t['03-01'].values)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_with_day_and_month_for_all_year (df):\n",
    "#     amount = 0\n",
    "#     am = 0\n",
    "#     for day in range(1, 32):\n",
    "#         for month in range (1, 13):\n",
    "#             if day < 10 and month < 10: \n",
    "# #                 print(day, month)\n",
    "#                 am += 1\n",
    "#                 pattern = r'\\d{4}-'+f'0{month}-'+f'0{day}'\n",
    "#                 tmp = df[df['DATE'].str.match(pattern)]\n",
    "#                 if tmp.empty:\n",
    "#                     amount += 1\n",
    "#                     print(pattern)\n",
    "#                     print(day, month)\n",
    "#                     print(tmp)\n",
    "# #                 pd.DataFrame(tmp).to_csv(f'Preprocessing/0{month}-0{day}.csv')\n",
    "#             if day < 10 and month > 9: \n",
    "# #                 print(day, month)\n",
    "#                 am += 1\n",
    "#                 pattern = r'\\d{4}-'+f'{month}-'+f'0{day}'\n",
    "#                 tmp = df[df['DATE'].str.match(pattern)]\n",
    "#                 if tmp.empty:\n",
    "# #                     print(pattern)\n",
    "# #                     amount += 1\n",
    "# #                     print(day, month)\n",
    "# #                     print(tmp)\n",
    "# #                 pd.DataFrame(tmp).to_csv(f'Preprocessing/{month}-0{day}.csv')\n",
    "#             if day > 9 and month < 10:\n",
    "# #                 print(day, month)\n",
    "#                 am += 1\n",
    "#                 pattern = r'\\d{4}-'+f'0{month}-'+f'{day}'\n",
    "#                 print(pattern)\n",
    "#                 tmp = df[df['DATE'].str.match(pattern)]\n",
    "#                 if tmp.empty:\n",
    "#                     amount += 1\n",
    "#                     print(day, month)\n",
    "#                     print(tmp)\n",
    "# #                 pd.DataFrame(tmp).to_csv(f'Preprocessing/0{month}-{day}.csv')\n",
    "#             if day > 9 and month > 9:\n",
    "# #                 print(day, month)\n",
    "#                 am += 1\n",
    "#                 pattern = r'\\d{4}-'+f'{month}-'+f'{day}'\n",
    "#                 tmp = df[df['DATE'].str.match(pattern)]\n",
    "#                 if tmp.empty:\n",
    "#                     amount += 1\n",
    "#                     print(pattern)\n",
    "#                     print(day, month)\n",
    "#                     print(tmp)\n",
    "#     print(amount)\n",
    "#     print(am)\n",
    "# #                 pd.DataFrame(tmp).to_csv(f'Preprocessing/0{month}-{day}.csv')\n",
    "# #                 print(tmp)\n",
    "# # спарсить к дате, чтобы дни и месяцы были нормальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df.drop(columns=['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'PRCP', 'PRCP_ATTRIBUTES', 'TAVG_ATTRIBUTES',\n",
    "#               'TMAX_ATTRIBUTES', 'TMIN_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES']).set_index('DATE') \n",
    "\n",
    "# TEMP_MIN['DATE'] = TEMP_MIN['DATE'].apply(pd.to_datetime, errors='ignore') \n",
    "# TEMP_MAX['DATE'] = TEMP_MIN['DATE'].apply(pd.to_datetime, errors='ignore') \n",
    "# TEMP_MIN.apply(pd.to_datetime(TEMP_MIN['DATE']), errors='ignore') \n",
    "# pd.to_datetime(TEMP_MAX['DATE'])\n",
    "# print(TEMP_MAX.head())\n",
    "# TEMP_MAX.info()\n",
    "# print(TEMP_MAX.head())\n",
    "# TEMP_MAX.info()\n",
    "# print(TEMP_MAX.head())\n",
    "# TEMP_MAX.info()\n",
    "# # print('______________________')\n",
    "# TEMP_MIN.info()\n",
    "# for i in range(len(TEMP_MAX['DATE'])):\n",
    "#     if TEMP_MAX['DATE'][i].day == 1 and TEMP_MAX['DATE'][i].month == 1:\n",
    "#         first_january = \n",
    "\n",
    "# plt.plot(TEMP_MAX['DATE'], TEMP_MAX['TMAX'])\n",
    "# month = 1\n",
    "# day = 1\n",
    "# d = datetime.strptime(f'{month}-{day}', '%m-%d')\n",
    "# print(str(d.day))\n",
    "# print(TEMP_MAX['DATE'][0])\n",
    "# # print('1970-01-01'==d)\n",
    "# print(re.match(d, TEMP_MAX['DATE'][0]))\n",
    "\n",
    "# for i in TEMP_MAX['DATE']:\n",
    "#     if re.match(r'\\d{4}-01-01', i):\n",
    "#          print()\n",
    "# d = r'\\d{4}-01-01'\n",
    "# TEMP_MAX[TEMP_MAX['DATE'].str.match(d)]   \n",
    "\n",
    "# TEMP_MIN[TEMP_MIN['DATE'].str.match(d)]\n",
    "# days = range(1,31)\n",
    "# print(days)\n",
    "# a=3\n",
    "# v=5\n",
    "# d=1990\n",
    "# # print(f'1990-0{a}-{v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tmp = pd.read_csv('Preprocessing/03-21.csv', delimiter=',', usecols = ['DATE', 'PRCP', 'TAVG', 'TMAX', 'TMIN'])\n",
    "\n",
    "# # tmp['DATE'] = tmp['DATE'].apply(pd.to_datetime, errors='ignore')\n",
    "# tmp = tmp.dropna()\n",
    "# tmp.describe()\n",
    "# tmp.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-60aca0d13d78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_box_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TMAX'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tmp' is not defined"
     ]
    }
   ],
   "source": [
    "draw_box_plot(tmp, 'TMAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_box_plot(tmp, 'TMIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_box_plot(tmp, 'TAVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_box_plot(tmp, 'PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = delete_outliers(tmp, 'TMAX')\n",
    "tmp = delete_outliers(tmp, 'TMIN')\n",
    "tmp = delete_outliers(tmp, 'TAVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tmp['DATE'], tmp['TMAX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = tmp.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбивка набора данных на тренировочное и тестовое подмножества\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = tmp.iloc[:, 0:4].values, tmp.iloc[:, 4].values\n",
    "X_train_, X_test_, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train, X_test = X_train_[:, 1:4], X_test_[:, 1:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ms = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_n = ms.fit_transform(X_train)\n",
    "X_test_n = ms.transform(X_test)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "#Fitting the Classifier\n",
    "from sklearn.svm import SVR\n",
    "classifier = SVR(C=1.0, cache_size=100, coef0=0.0, degree=3, epsilon=0.1,\n",
    "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "classifier_std = SVR(C=10.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "classifier.fit(X_train_n, y_train)\n",
    "classifier_std.fit(X_train_std, y_train)\n",
    "\n",
    "prediction = classifier.predict(X_test_n)\n",
    "prediction1 = classifier_std.predict(X_test_std)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "prediction2 = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(5,), max_iter=5000, \n",
    "                   activation='identity', solver='adam', alpha=0.001,\n",
    "                           random_state=1, learning_rate_init=0.01)\n",
    "mlp.fit(X_train_n, y_train)\n",
    "prediction_mlp = mlp.predict(X_test_n)\n",
    "\n",
    "print(\"SVM\")\n",
    "print('The Explained Variance: %.2f' % classifier_std.score(X_test_std, y_test))\n",
    "print('The Mean Absolute Error: %.2f degrees celcius' % mean_absolute_error(\n",
    "    y_test, prediction1))\n",
    "print('The Median Absolute Error: %.2f degrees celcius' %\n",
    "      median_absolute_error(y_test, prediction1))\n",
    "\n",
    "print('\\nLinear regression')\n",
    "print(\"The Explained Variance: %.2f\" % regressor.score(X_test, y_test))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction2))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction2))  \n",
    "\n",
    "print('\\nMLP')\n",
    "print(\"The Explained Variance: %.2f\" % mlp.score(X_test_n, y_test))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction_mlp))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction_mlp))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['DATE', 'TMIN']\n",
    "df_real = pd.DataFrame({'DATE': X_test_[:, 0], 'TMIN': y_test, 'TMIN_pred _SVM': prediction1, 'TMIN_pred _Lin_Regr': prediction2, 'TMIN_pred _MLP': prediction_mlp})\n",
    "df_pred = pd.DataFrame({'DATE': X_test_[:, 0], 'TMIN': prediction1})\n",
    "# df_real = df_real['DATE'].apply(pd.to_datetime, errors='ignore')\n",
    "df_real.set_index('DATE')\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "df_real.plot(x = 'DATE', color = [\"dodgerblue\", 'r', 'darkmagenta', 'g'], style = ['', '--', '-', '-.'],linewidth=1, figsize=(15,15), )\n",
    "# df_real = df_real.groupby('DATE')['TMIN'].mean()\n",
    "# df_pred = df_pred.groupby('DATE')['TMIN'].mean()\n",
    "# p1 = df_real.plot(color = \"dodgerblue\", linewidth=2, label = \"Real\")\n",
    "# p2 = df_pred.plot(linestyle='--', color = 'r', linewidth=2, label = \"Prediction\")\n",
    "# plt.legend(handles=[p1, p2])\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=75)\n",
    "plt.xlabel('Date')    \n",
    "plt.ylabel('Min temperature, $^o, C$')    \n",
    "plt.title('Предсказание минимальной температуры', fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot_date(df_real['DATE'], df_real['TMIN'], linestyle='--')\n",
    "# plt.plot(df_real['DATE'], df_real['TMIN'], color='b')\n",
    "# plt.plot(X_test_[:, 0], prediction1, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбивка набора данных на тренировочное и тестовое подмножества\n",
    "# tmp1 = tmp['DATE', 'TMIN', 'TMAX']\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# print(tmp)\n",
    "\n",
    "# X, y = tmp.iloc[0:-1, 4].values, tmp.iloc[-1, 4]\n",
    "# # X_train, X_test, y_train_, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# # X_train, X_test = X_train_[:, 1], X_test_[:, 2]\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression  \n",
    "# regressor = LinearRegression()\n",
    "# t = np.array(X.T).reshape((-1, 1))\n",
    "# # t_train = np.array(X_test).reshape((-1, 1))\n",
    "# regressor.fit(t, y_train)\n",
    "# # prediction = regressor.predict(t_train)\n",
    "\n",
    "# from sklearn.metrics import mean_absolute_error, median_absolute_error  \n",
    "# # print(\"The Explained Variance: %.2f\" % regressor.score(t_train, y_test))  \n",
    "# print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction))  \n",
    "# print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = (datetime.now() - timedelta(60)).strftime('%y-%m-%d')\n",
    "\n",
    "data = delete_outliers(pd.read_csv('Preprocessing/03-21.csv', delimiter=',', index_col='DATE'), '03-21')\n",
    "data1 = delete_outliers(pd.read_csv('Preprocessing/03-22.csv', delimiter=',', index_col='DATE'), '03-22')\n",
    "data2 = delete_outliers(pd.read_csv('Preprocessing/03-23.csv', delimiter=',', index_col='DATE'), '03-23')\n",
    "data3 = delete_outliers(pd.read_csv('Preprocessing/03-24.csv', delimiter=',', index_col='DATE'), '03-24')\n",
    "data4 = delete_outliers(pd.read_csv('Preprocessing/03-25.csv', delimiter=',', index_col='DATE'), '03-25')\n",
    "data5 = delete_outliers(pd.read_csv('Preprocessing/03-26.csv', delimiter=',', index_col='DATE'), '03-26')\n",
    "data6 = delete_outliers(pd.read_csv('Preprocessing/03-27.csv', delimiter=',', index_col='DATE'), '03-27')\n",
    "data7 = delete_outliers(pd.read_csv('Preprocessing/03-28.csv', delimiter=',', index_col='DATE'), '03-28')\n",
    "data8 = delete_outliers(pd.read_csv('Preprocessing/03-29.csv', delimiter=',', index_col='DATE'), '03-29')\n",
    "data9 = delete_outliers(pd.read_csv('Preprocessing/03-30.csv', delimiter=',', index_col='DATE'), '03-30')\n",
    "\n",
    "data10 = pd.read_csv('Preprocessing/04-01.csv', delimiter=',', index_col='DATE')\n",
    "\n",
    "def rename_cols_rows(data):\n",
    "    data['DATE'] = data['DATE'].apply(pd.to_datetime, errors='ignore')\n",
    "    year = data['DATE'].map(lambda x: x.year)\n",
    "    day_month = data['DATE'].map(lambda x:x.strftime('%m-%d')).unique()[0]\n",
    "    return data.drop('DATE', 1).set_index(year).rename(columns={'TMAX': f'{day_month}'})\n",
    "\n",
    "df = pd.concat([data, data1, data2, data3, data4, data5, data6, data7, data8, data9, data10], axis = 1, join='outer', sort=True)\n",
    "df = df.dropna()\n",
    "df = df.T\n",
    "print(df)\n",
    "# df2 = data.merge(data1, on='DATE', how='outer', left_index=True, right_index=True)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t1 = t.apply(lambda x: delete_outliers(x))\n",
    "t1 = t1.dropna()\n",
    "# t1.info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = t1.iloc[:, :-1].values, t1.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# X_train, X_test = X_train_[:, 1], X_test_[:, 2]\n",
    "X_train, X_test, y_train, y_test = np.array(X[:-4]), np.array(X[-4:]), np.array(y[:-4]), np.array(y[-4:])\n",
    "# print(X_test.shape)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Explained Variance: 1.00\n",
      "The Mean Absolute Error: 4.56 degrees celsius\n",
      "The Median Absolute Error: 4.00 degrees celsius\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "prediction1 = regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score\n",
    "\n",
    "\n",
    "print(\"The Explained Variance: %.2f\" % regressor.score(X_train, y_train))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction1))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "The Explained Variance: 0.97\n",
      "The Mean Absolute Error: 4.39 degrees celcius\n",
      "The Median Absolute Error: 4.04 degrees celcius\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "#Fitting the Classifier\n",
    "SVR = SVR(C=10.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "SVR.fit(X_train_std, y_train)\n",
    "\n",
    "prediction = SVR.predict(X_test_std)\n",
    "print(\"SVM\")\n",
    "print('The Explained Variance: %.2f' % SVR.score(X_train_std, y_train))\n",
    "print('The Mean Absolute Error: %.2f degrees celcius' % mean_absolute_error(\n",
    "    y_test, prediction))\n",
    "print('The Median Absolute Error: %.2f degrees celcius' %\n",
    "      median_absolute_error(y_test, prediction))\n",
    "\n",
    "# Specifies the kernel type to be used in the algorithm. \n",
    "# It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. \n",
    "# If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP\n",
      "The Explained Variance: -0.00\n",
      "The Mean Absolute Error: 5.03 degrees celsius\n",
      "The Median Absolute Error: 4.86 degrees celsius\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ms = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_n = ms.fit_transform(X_train)\n",
    "X_test_n = ms.transform(X_test)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(3,), max_iter=5000, \n",
    "                   activation='logistic', solver='adam', alpha=0.001,\n",
    "                           random_state=1, learning_rate_init=0.01)\n",
    "mlp.fit(X_train_n, y_train)\n",
    "prediction_mlp = mlp.predict(X_test_n)\n",
    "\n",
    "print('\\nMLP')\n",
    "print(\"The Explained Variance: %.2f\" % mlp.score(X_train_n, y_train))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction_mlp))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree\n",
      "The Explained Variance: -0.00\n",
      "The Mean Absolute Error: 3.45 degrees celsius\n",
      "The Median Absolute Error: 3.40 degrees celsius\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X_train_n, y_train)\n",
    "prediction_DT = clf.predict(X_test_n)\n",
    "\n",
    "print('\\nDecision Tree')\n",
    "print(\"The Explained Variance: %.2f\" % mlp.score(X_train_n, y_train))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction_DT))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-31-1b5864e2f621>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-1b5864e2f621>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    random_state=0, shuffle=False)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "                       random_state=0, shuffle=False)\n",
    "regr = AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear', n_estimators=100, random_state=0)\n",
    "regr.fit(X_train_std, y_train)  \n",
    "\n",
    "prediction_Ada_Boost = regr.predict(X_test_std)\n",
    "\n",
    "print('\\nDecision Tree')\n",
    "print(\"The Explained Variance: %.2f\" % regr.score(X_train_std, y_train))  \n",
    "print(\"The Mean Absolute Error: %.2f degrees celsius\" % mean_absolute_error(y_test, prediction_Ada_Boost))  \n",
    "print(\"The Median Absolute Error: %.2f degrees celsius\" % median_absolute_error(y_test, prediction_Ada_Boost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation : {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default ‘relu’\n",
    "# Activation function for the hidden layer.\n",
    "# ‘square’, ‘exponential’\n",
    "# ‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "# ‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "# ‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "# ‘relu’, the rectified linear unit function, returns f(x) = max(0, x)\n",
    "# solver : {‘lbfgs’, ‘sgd’, ‘adam’}, default ‘adam’\n",
    "# The solver for weight optimization.\n",
    "\n",
    "# ‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n",
    "# ‘sgd’ refers to stochastic gradient descent.\n",
    "# ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'TEMP': y_test, 'TEMP_LR': prediction1, 'TEMP_SCR': prediction, 'TEMP_MLP': prediction_mlp, 'TEMP_DT': prediction_DT, 'TEMP_Ada_Boost': prediction_mlp})\n",
    "\n",
    "df.plot(y = ['TEMP', 'TEMP_SCR', 'TEMP_MLP', 'TEMP_Ada_Boost'],color = [\"dodgerblue\", 'r', 'y', 'g', 'darkmagenta', 'pink'], style = ['', '--', '-', '-.', ''],linewidth=1, figsize=(25,10), )\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=75)\n",
    "plt.xlabel('Date')    \n",
    "plt.ylabel('Max temperature, $^o, C$')    \n",
    "plt.title('Предсказание  максимальной температуры', fontsize=14, fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
